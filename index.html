<!DOCTYPE HTML>
<html lang="en">
<head>
    <!-- Meta and Title -->
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Tomer Galanti</title>
    <meta name="author" content="Tomer Galanti">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- Stylesheets -->
    <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css"/>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css"/>
    <link rel="stylesheet" type="text/css" href="stylesheet.css"/>
    <link href="https://fonts.googleapis.com/css2?family=Amiri:ital,wght@0,400;0,700;1,400;1,700&display=swap" rel="stylesheet"/>

    <!-- Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-164383547-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-W36V9ZRFP4');
    </script>

    <!-- Image Script -->
    <script type="text/javascript">
        var imageURLs = ["/images/logo.png"];
        function getImageTag() {
            var randomIndex = Math.floor(Math.random() * imageURLs.length);
            return `<a href="${imageURLs[randomIndex]}"><img src="${imageURLs[randomIndex]}" alt="profile photo", class="rounded-image"></a>`;
        }
    </script>

    <!-- Styles -->
    <style>
        .content-wrapper {
            width: 50%;
            margin: 0 auto;
        }
        .top-buttons {
            position: absolute;
            top: 20px;
            right: 20px;
            display: grid;
            grid-template-columns: repeat(1, auto);
            gap: 10px;
        }
        .top-buttons a {
            width: 80px;
            height: 30px;
            display: inline-block;
            background-color: white;
            color: navy;
            border: none;
            border-radius: 5px;
            cursor: pointer;
            text-align: center;
            text-decoration: none;
            font-size: 12px;
            font-family: Arial, sans-serif;
            line-height: 30px;
            margin-left: 10px;
        }
        .logo {
        width: 120px;
        height: 120px;
        border-radius: 70%;
        object-fit: cover;
        margin-bottom: 5px;
        border: 2px solid #ccc;
        }
        .about-section {
            display: flex;
            align-items: flex-start;
            margin-top: 20px;
        }
        .text-content {
            flex: 1;
        }
        .image-content {
            margin-left: 20px;
            margin-top: 20px; /* Adjust this value to move the image lower */
        }
        .image-content img {
            max-width: 200px;
            height: auto;
        }
        .contact-links {
            margin-top: 20px;
        }
        .rounded-image {
        border-radius: 12px;
        }
        .contact-links a {
            display: inline-block;
            margin-right: 15px;
            font-size: 14px;
            text-decoration: none;
            color: navy;
        }
        .contact-links a:hover {
            text-decoration: underline;
        }
        h2 {
            font-size: 24px;
            margin-top: 30px;
        }
        p {
            font-size: 16px;
            line-height: 1.2;
        }
        ul {
            margin-left: 0;
            padding-left: 0;
            list-style-position: inside; /* Ensures bullets align with text */
        } ul 
        li {
            margin-bottom: 10px;
        }
        /* Optional: Adjust the maximum width for better responsiveness */
        @media (max-width: 800px) {
            .content-wrapper {
                width: 90%;
            }
            .about-section {
                flex-direction: column;
                align-items: center;
            }
            .image-content {
                margin-left: 0;
                margin-top: 20px;
            }
        }
    </style>
</head>
<body>
    <!-- Navigation Buttons -->
    <div class="top-buttons">
        <a href="index.html">Home</a>
        <a href="PI.html">About the PI</a>
        <a href="publications.html">Publications</a>
        <a href="preprints.html">Preprints</a>
        <a href="activities.html">Activities</a>
        <a href="teaching.html">Teaching</a>
        <a href="group.html">Group</a>
        <a href="apply.html">Apply</a>
    </div>

    <!-- Main Content Wrapper -->
    <div class="content-wrapper">
        <!-- Name -->

        <!-- About Section with Image -->
        <div class="about-section">
            <!-- Text Content -->
            <div class="text-content">
                <h2>About us</h2>
                <p>
                    Howdy! üëã We are the Deep Learning Fundamentals group at <a href="https://engineering.tamu.edu/cse/index.html" class="links">Texas A&M University</a> led by Prof. Tomer Galanti. 
                    Utilizing both theory and experiments, our research develops realistic models of contemporary learning settings to guide practices in deep learning and LLMs. 
                    <br><br>
                    Our group loves science and we enjoy collaborating. If you are curious about our work, please reach out!                    
                </p>
                <!-- Contact Links -->
                <div class="contact-links">
                    Lab GitHub: &nbsp;&nbsp;<a href="https://github.com/DLFundamentals"><span class="social-icon fa fa-github"></span></a>&nbsp;
                </div>
            </div>

            <!-- Image Content -->
            <div class="image-content">
                <script type="text/javascript">
                    document.write(getImageTag());
                </script>
            </div>
        </div>

        <!-- Research Section -->
        <h2>Research</h2>
        <p>
            
        </p>
        <ul>
            <li>
                <em><strong>What types of data representations are learned by neural networks?</strong></em> In [<a href="https://openreview.net/forum?id=0LzE9AROwD#discussion">1</a>] we showed that the ranks of the weight matrices are controlled by the training hyperparameters in modern neural networks (with residual connections, self-attention, convolutional layers, etc.). In [<a href="https://openreview.net/forum?id=162TqkUNPO">2</a>, <a href="https://proceedings.mlr.press/v202/rangamani23a.html">3</a>], we demonstrated how neural collapse propagates into intermediate layers of trained classifiers, and in [<a href="https://arxiv.org/abs/2305.15614">4</a>], we showed that self-supervised learning algorithms produce representations that cluster based on semantic attributes. Recently, in [<a href="https://arxiv.org/abs/2410.03006">5</a>], we introduced a framework unifying key deep learning phenomena, including neural collapse and the neural Ansatz, by explaining how latent representations, weights, and neuron gradients align during training.
            </li>
            <li>
               <em><strong>How various properties of latent representations affect the model's compressibility and its ability to generalize and adapt to different tasks?</strong></em> For example, in [<a href="https://openreview.net/forum?id=SwIp410B6aQ">6</a>, <a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136970625.pdf">7</a>, <a href="https://openreview.net/forum?id=VrK7pKwOhT_">8</a>, <a href="https://arxiv.org/abs/2212.12532">9</a>], we developed theory and algorithms linking clustering properties, such as neural collapse, to the ability of pre-trained classifiers to adapt to downstream tasks with minimal data. For compressibility, the results in [<a href="https://arxiv.org/abs/2206.05794">1</a>] show how the training hyperparameters control the network's compressibility. Furthermore, in [<a href="https://arxiv.org/abs/2301.12033">10</a>], we showed how hard-coded architectural sparsity, such as in convolutional networks, enhances generalization.
            </li>
            <li>
                I also develop <em><strong>theory and algorithms for effectively training and accelerating LLMs</strong></em>. In [<a href="https://arxiv.org/abs/2405.14105">11</a>], we introduced the Distributed Speculative Inference (DSI) algorithm, which accelerates LLM inference using multiple GPUs. DSI introduces a novel type of task parallelism called <em>Speculation Parallelism (SP)</em>, which balances computational resources and latency by overlapping target and drafter instances. In [<a href="https://arxiv.org/abs/2409.19150v1">12</a>], we demonstrated how to effectively train Autoregressive Decision Trees as coherent and grammatically correct language models. Finally, in [<a href="">13</a>], we proposed the <em>‚ÄúFair Language Model Dilemma,‚Äù</em> asserting that increasing weight decay leads to a tendency to neglect low-frequency tokens, which is detrimental to the model‚Äôs performance since low-frequency tokens constitute the majority of the vocabulary.
            </li>
        </ul>
    </div>
</body>
</html>
