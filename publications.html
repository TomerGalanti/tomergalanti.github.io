<!DOCTYPE HTML>
<html lang="en">

 <!-- Global Site Tag (gtag.js) - Google Analytics -->
 <script async src="https://www.googletagmanager.com/gtag/js?id=UA-164383547-1"></script>

<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-W36V9ZRFP4');
</script>

<!-- google_analytics: UA-164383547-1 -->

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Tomer Galanti</title>

  <meta name="author" content="Tomer Galanti">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Academicons -->
  <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css"/>

  <!-- TO HAVE ICONS -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <!-- <link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"> -->

  <link rel="stylesheet" type="text/css" href="stylesheet.css">

  <!-- RANDOM IMAGE! with Java Scripts -->
  <script type="text/javascript">
    var imageURLs = [
       "/images/Tomer Galanti 2.JPG"
    ];
    function getImageTag() {
      var randomIndex = Math.floor(Math.random() * imageURLs.length);
      var img = '<a href=\"'
      img += imageURLs[randomIndex];
      img += '\"><img src=\"';
      img += imageURLs[randomIndex];
      img += '\" style="width:80%;max-width:80%" alt="profile photo"></a>';
      return img;
    }
  </script>

<style>
body {
            background-color: #f2e8da; /* soft light brown */
        }
.top-buttons {
position: absolute;
top: 20px;
right: 20px;
display: grid;
grid-template-columns: repeat(1, auto);
gap: 10px;
}

.top-buttons a {
width: 80px;
height: 30px;
display: inline-block;
background-color: white;
color: navy;
border: none;
border-radius: 5px;
cursor: pointer;
text-align: center;
text-decoration: none;
font-size: 12px;
font-family: Arial, sans-serif;
line-height: 30px;
margin-left: 10px;
}

/* .top-buttons a:hover {
background-color: #0056b3;
} */

  .content-wrapper {
      width: 50%;
      margin: 0 auto;
  }
</style>

</head>

<body>

<div class="top-buttons">
  <a href="index.html">Home</a>
  <a href="PI.html">About the PI</a>
  <a href="publications.html">Publications</a>
  <a href="preprints.html">Preprints</a>
  <a href="activities.html">Activities</a>
  <a href="teaching.html">Teaching</a>
  <a href="group.html">Group</a>
  <a href="apply.html">Apply</a>
</div>

<div class="content-wrapper">
<table
style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
<tbody>
<tr>
<td style="padding:20px;width:100%;vertical-align:middle">
<!-- <heading>Publications</heading> -->
</td>
</tr>
<tr>
<td style="padding:20px;width:95%;vertical-align:middle;">
<div style="padding-left:0px;">

<p><a href="https://openreview.net/forum?id=0LzE9AROwD#discussion"><strong>SGD and Weight Decay Secretly Minimize the Rank of Your Neural Network</strong></a><br />
T. Galanti, Z. Siegel, A. Gupte, T. Poggio<br />
<em>Conference on Parsimony and Learning,&nbsp;</em>CPAL, 2025<br />
<em>NeurIPS Workshop on Mathematics of Modern Machine Learning,&nbsp;</em>M3L, 2024</p>    

<p><a href="https://openreview.net/forum?id=cJd1BgZ9CS"><strong>Distributed Speculative Inference (DSI): Speculation Parallelism for Provably Faster Lossless Language Model Inference</strong></a><br />
N. Timor, J. Mamou, D. Korat, M. Berchansky, O. Pereg, M. Wasserblat, T. Galanti, M. Gordon, D. Harel<br />
<em>International Conference on Learning Representations,&nbsp;</em>ICLR, 2025</p>    

<p><a href="https://openreview.net/forum?id=Njx1NjHIx4&noteId=MYV5SMYpzo"><strong>Formation of Representations in Neural Networks</strong></a><br />
L. Ziyin, I. L. Chuang, T. Galanti, T. Poggio<br />
<em>International Conference on Learning Representations,&nbsp;</em>ICLR, 2025<br />
<strong style="background-color: rgb(244, 244, 113); padding: 2px;">Spotlight presentation (5% acceptance)</strong></p>

<p><a href="https://openreview.net/forum?id=nge5deRsEH"><strong>On the Power of Decision Trees in Auto-Regressive Language Modeling</strong></a><br />
Y. Gan, T. Galanti, T. Poggio, E. Malach<br />
<em>Neural Information Processing Systems,&nbsp;</em>NeurIPS, 2024</p>

<p><a href="https://arxiv.org/abs/2405.14105"><strong>Distributed Speculative Inference of Large Language Models is Provably Faster</strong></a><br />
N. Timor, J. Mamou, D. Korat, M. Berchansky, O. Pereg, M. Wasserblat, T. Galanti, M. Gordon, D. Harel<br />
<em>NeurIPS Workshop on Efficient Natural Language and Speech Processing&nbsp;</em>(ENLSP), 2024 (published at PMLR)<em>.</em></p>

<p><a href="https://openreview.net/forum?id=COPzNA10hZ"><strong>Norm-Based Generalization Bounds for Sparse Neural Networks</strong></a><br />
T. Galanti, M. Xu, L. Galanti, T. Poggio<br />
<em>Neural Information Processing Systems,&nbsp;</em>NeurIPS, 2023</p>

<p><a href="https://openreview.net/forum?id=NsVEjx6YPd&noteId=uxqa0UxtZk"><strong>Reverse Engineering Self-Supervised Learning</strong></a><br />
I. Ben-Shaul, R. Shwartz-Ziv*, T. Galanti*, S. Dekel, Y. LeCun<br />
<em>Neural Information Processing Systems, </em>NeurIPS, 2023</p>

<p><a href="https://openreview.net/forum?id=162TqkUNPO"><strong>Comparative Generalization Bounds for Deep Neural Networks</strong></a><br />
T. Galanti, L. Galanti, I. Ben-Shaul<br />
<em>Transactions in Machine Learning Research,&nbsp;</em>TMLR, 2023</p>

<p><a href="https://openreview.net/forum?id=sWQJfb2GSk"><strong>Exploring the Approximation Capabilities of Multiplicative Neural Networks for Smooth Functions</strong></a><br />
I. Ben-Shaul, T. Galanti, S. Dekel<br />
<em>Transactions in Machine Learning Research</em>, TMLR, 2023</p>

<p><a href="https://proceedings.mlr.press/v202/rangamani23a.html"><strong>Feature Learning in Deep Classifiers Through Intermediate Neural Collapse</strong></a><br />
A. Rangamani, M. Lindegaard, T. Galanti, T. Poggio<br />
<em>International Conference on Machine Learning</em>,<em> </em>ICML,<em>&nbsp;</em>2023</p>

<p><a href="https://spj.science.org/doi/10.34133/research.0024"><strong>Dynamics of Deep Classifiers Trained with the Square Loss: Normalization, Low Rank, Neural Collapse and Generalization Bounds</strong></a><br />
M. Xu, A. Rangamani, Q. Liao, T. Galanti, T. Poggio<br />
<em>Research (a Science partner journal),&nbsp;</em>2023</p>

<p><a href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136970625.pdf"><strong>Image2Point: 3D Point-Cloud Understanding with 2D Image Pretrained Models</strong></a><br />
C. Xu, S. Yang, T. Galanti, B. Wu, X. Yue, B. Zhai, W. Zhan, P. Vajda, K. Keutzer, M. Tomizuka<br />
<em>IEEE European Conference on Computer Vision</em>, ECCV, 2022</p>

<p><a href="https://openreview.net/pdf?id=VrK7pKwOhT_"><strong>Improved Generalization Bounds for Transfer Learning via Neural Collapse</strong></a><br />
T. Galanti, A. Gyorgy, M. Hutter<br />
<em>ICML Workshop on Pretraining: Perspectives, Pitfalls and Paths Forward, </em>2022</p>

<p><a href="https://arxiv.org/abs/2202.09028"><strong>On the Implicit Bias Towards Depth Minimization in Deep Neural Networks</strong></a><br />
T. Galanti, L. Galanti, I. Ben-Shaul<br />
<em>Conference on the Mathematical Theory of Deep Neural Networks</em>, DEEPMATH, 2022<br />
<em>Workshop on the Theory of Overparameterized Machine Learning</em>, TOPML, 2022</p>

<p><a href="https://openreview.net/forum?id=SwIp410B6aQ"><strong>On the Role of Neural Collapse in Transfer Learning</strong></a><br />
T. Galanti, A. Gyorgy, M. Hutter<br />
<em>International Conference on Learning Representations</em>, ICLR, 2022</p>

<p><a href="https://proceedings.mlr.press/v177/ali22a.html"><strong>Weakly Supervised Discovery of Semantic Attributes</strong></a><br />
A. A. Ali, T. Galanti, E. Zheltonozhskii, C. Baskin, L. Wolf<br />
<em>Causal Learning and Reasoning</em>, CLeaR, 2022</p>

<p><a href="https://openreview.net/forum?id=xfskdMFkuTS"><strong>Meta Internal Learning</strong></a><br />
R. Ben Sadoun, S. Gur, T. Galanti, L. Wolf<br />
<em>Neural Information Processing Systems,&nbsp;</em>NeurIPS, 2021</p>

<p><a href="https://proceedings.mlr.press/v161/littwin21a.html"><strong>On Random Kernels of Residual Architectures</strong></a><br />
E. Littwin*, T. Galanti*, L. Wolf<br />
<em>Uncertainty in Artificial Intelligence</em>, UAI, 2021</p>

<p><a href="https://jmlr.org/papers/v22/18-489.html"><strong>Risk Bounds for Unsupervised Cross-Domain Mapping with IPMs</strong></a><br />
T. Galanti, S. Benaim, L. Wolf<br />
<em>Journal of Machine Learning Research</em>, JMLR, 2021</p>

<p><a href="https://link.springer.com/article/10.1007/s11263-020-01424-w"><strong>Evaluation Metrics for Conditional Image Generation</strong></a><br />
Y. Benny, T. Galanti, S. Benaim, L. Wolf<br />
<em>International Journal of Computer Vision</em>, IJCV, 2021</p>

<p><a href="https://proceedings.neurips.cc/paper/2020/hash/75c58d36157505a600e0695ed0b3a22d-Abstract.html"><strong>On the Modularity of Hypernetworks&nbsp;</strong></a><br />
T. Galanti, L. Wolf<br />
<em>Neural Information Processing Systems</em>, NeurIPS, 2020<br />
<strong style="background-color: rgb(244, 244, 113); padding: 2px;">Oral presentation (1% acceptance)</strong></p>

<p><a href="https://proceedings.neurips.cc/paper/2020/hash/999df4ce78b966de17aee1dc87111044-Abstract.html"><strong>On Infinite-Width Hypernetworks</strong></a><br />
E. Littwin*, T. Galanti*, L. Wolf<br />
<em>Neural Information Processing Systems</em>, NeurIPS, 2020</p>

<p><a href="https://openaccess.thecvf.com/content_ICCV_2019/html/Benaim_Domain_Intersection_and_Domain_Difference_ICCV_2019_paper.html"><strong>Domain Intersection and Domain Difference</strong></a><br />
S. Benaim, M. Khaitov, T. Galanti, L. Wolf<br />
<em>IEEE International Conference on Computer Vision</em>, ICCV, 2019</p>

<p><strong><a href="https://openreview.net/forum?id=H1lqZhRcFm">Unsuperivsed Learning of the Set of Local Maxima</a> </strong><br />
L. Wolf, S. Benaim, T. Galanti<br />
<em>International Conference on Learning Representations</em>, ICLR, 2019</p>

<p><a href="https://openreview.net/forum?id=BylE1205Fm"><strong>Emerging Disentanglement in Auto-Encoder Based Unsupervised Image Content Transfer</strong></a><br />
O. Press, T. Galanti, S. Benaim, L. Wolf<br />
<em>International Conference on Learning Representations</em>, ICLR, 2019</p>

<p><a href="https://dl.acm.org/doi/abs/10.1145/3306618.3314260"><strong>A Formal Approach to Explainability</strong></a><br />
L. Wolf, T. Galanti, T. Hazan<br />
<em>Artificial Intelligence, Ethics and Society</em>, AIES, 2019</p>

<p><a href="http://nips2018dltheory.rice.edu/"><strong>Generalization Bounds for Cross-Domain Mapping with WGANs</strong></a><br />
T. Galanti, S. Benaim, L. Wolf<br />
<em>NeurIPS Workshop on Integration of Deep Learning Theories</em>, 2018</p>

<p><a href="https://openaccess.thecvf.com/content_ECCV_2018/html/Lior_Wolf_Estimating_the_Success_ECCV_2018_paper.html"><strong>Estimating the Success of Unsupervised Image to Image Translation</strong></a><br />
S. Benaim*, T. Galanti*, L. Wolf<br />
<em>IEEE European Conference on Computer Vision</em>, ECCV, 2018</p>

<p><a href="https://openreview.net/forum?id=H1VjBebR-"><strong>The Role of Minimal Complexity in Unsupervised Learning of Semantic Mappings</strong></a><br />
T. Galanti, L. Wolf, S. Benaim<br />
<em>International Conference on Learning Representations</em>, ICLR, 2018</p>

<p><a href="https://academic.oup.com/imaiai/article-abstract/5/2/159/2363463?redirectedFrom=fulltext"><strong>A Theoretical Framework for Deep Transfer Learning</strong></a><br />
T. Galanti, T. Hazan, L. Wolf<br />
<em>Information and Inference: A Journal of the IMA</em>, IMAIAI, 2016<br />        
</div>
</td>
</tr>
</tbody>
</table>
</div>

</body>

</html>